{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías necesarias\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1728676400 # Esta semilla fue creada usando la función time().\n",
    "# Establecer la semilla global para Tensorflow\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "\"\"\"\n",
    "El dataset de Kaggle que se utilizó para entrenar el modelo es el siguiente: https://www.kaggle.com/datasets/balabaskar/wonders-of-the-world-image-classification. En kaggle tenemos el dataset original dentro de un directorio cada uno con subdirectorio por cada categoría. En este repositorio tenemos estos subdirectorios dentro del directorio dataset completo. Vamos a definir una función para dividir las imágenes en los sets de entrenamiento, validación y prueba, para lo que creamos tres directorios (test, val y dir) cada uno con un subdirectorio para cada una de las categorías del dataset. Implementamos esto con la función create_directories. \n",
    ":param source_dir: Directorio de origen que contiene las carpetas.\n",
    ":param dest_dirs: Lista de directorios de destino donde se crearán las carpetas.\n",
    "\"\"\"\n",
    "\n",
    "def create_directories(source_dir, dest_dirs):\n",
    "    for category in os.listdir(source_dir):\n",
    "        category_path = os.path.join(source_dir, category)\n",
    "        if os.path.isdir(category_path):\n",
    "            for dest_dir in dest_dirs:\n",
    "                dest_category_dir = os.path.join(dest_dir, category)\n",
    "                os.makedirs(dest_category_dir, exist_ok=True)\n",
    "\n",
    "# Directorio de origen\n",
    "source_dir = './dataset completo'\n",
    "\n",
    "# Directorios de destino\n",
    "train_dir = './train'\n",
    "val_dir = './val'\n",
    "test_dir = './test'\n",
    "\n",
    "# Crear directorios\n",
    "create_directories(source_dir, [train_dir, val_dir, test_dir])\n",
    "\n",
    "def split_data(source_dir, train_dir, val_dir, test_dir, val_split=0.15, test_split=0.15):\n",
    "\n",
    "    for category in os.listdir(source_dir):\n",
    "        category_path = os.path.join(source_dir, category)\n",
    "        if os.path.isdir(category_path):\n",
    "            images = os.listdir(category_path)\n",
    "            random.shuffle(images)\n",
    "            num_images = len(images)\n",
    "            num_test = int(num_images * test_split)\n",
    "            num_val = int(num_images * val_split)\n",
    "            num_train = num_images - num_test - num_val\n",
    "\n",
    "            train_images = images[:num_train]\n",
    "            val_images = images[num_train:num_train + num_val]\n",
    "            test_images = images[num_train + num_val:]\n",
    "\n",
    "            for image in train_images:\n",
    "                shutil.move(os.path.join(category_path, image), os.path.join(train_dir, category, image))\n",
    "            for image in val_images:\n",
    "                shutil.move(os.path.join(category_path, image), os.path.join(val_dir, category, image))\n",
    "            for image in test_images:\n",
    "                shutil.move(os.path.join(category_path, image), os.path.join(test_dir, category, image))\n",
    "\n",
    "# Directorios de origen y destino\n",
    "source_dir = './dataset completo'\n",
    "train_dir = './train'\n",
    "val_dir = './val'\n",
    "test_dir = './test'\n",
    "\n",
    "# Dividir los datos\n",
    "split_data(source_dir, train_dir, val_dir, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2305 images belonging to 12 classes.\n",
      "Found 401 images belonging to 12 classes.\n",
      "Found 570 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generadores de datos con ImageDataGenerator\n",
    "datagen_train = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    ")\n",
    "\n",
    "datagen_test = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = datagen_train.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    subset='training'\n",
    "    class_mode='categorical',\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "val_generator = datagen_train.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "test_generator = datagen_test.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m83683744/83683744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Cargar modelo preentrenado Xception\n",
    "base_model = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ xception (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,861,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,300</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ xception (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m20,861,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m2,098,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │        \u001b[38;5;34m12,300\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,971,956</span> (87.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,971,956\u001b[0m (87.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,110,476</span> (8.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,110,476\u001b[0m (8.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,861,480</span> (79.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,861,480\u001b[0m (79.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear el modelo\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(train_generator.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 01:22:06.079261: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 50466816 exceeds 10% of free system memory.\n",
      "2024-10-21 01:22:06.895488: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 97329152 exceeds 10% of free system memory.\n",
      "2024-10-21 01:22:07.230958: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 97329152 exceeds 10% of free system memory.\n",
      "2024-10-21 01:22:07.231052: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 49561600 exceeds 10% of free system memory.\n",
      "2024-10-21 01:22:07.841307: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 194658304 exceeds 10% of free system memory.\n",
      "/home/vscode/.local/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 - 193s - 3s/step - accuracy: 0.6772 - loss: 1.0023 - val_accuracy: 0.7731 - val_loss: 0.6727\n",
      "Epoch 2/30\n",
      "73/73 - 192s - 3s/step - accuracy: 0.8148 - loss: 0.5492 - val_accuracy: 0.8429 - val_loss: 0.4739\n",
      "Epoch 3/30\n",
      "73/73 - 198s - 3s/step - accuracy: 0.8529 - loss: 0.4342 - val_accuracy: 0.8778 - val_loss: 0.3906\n",
      "Epoch 4/30\n",
      "73/73 - 203s - 3s/step - accuracy: 0.8538 - loss: 0.4361 - val_accuracy: 0.8429 - val_loss: 0.4565\n",
      "Epoch 5/30\n",
      "73/73 - 176s - 2s/step - accuracy: 0.8646 - loss: 0.3885 - val_accuracy: 0.8728 - val_loss: 0.3897\n",
      "Epoch 6/30\n",
      "73/73 - 202s - 3s/step - accuracy: 0.8937 - loss: 0.3432 - val_accuracy: 0.8953 - val_loss: 0.3495\n",
      "Epoch 7/30\n",
      "73/73 - 195s - 3s/step - accuracy: 0.8876 - loss: 0.3439 - val_accuracy: 0.8803 - val_loss: 0.3854\n",
      "Epoch 8/30\n",
      "73/73 - 204s - 3s/step - accuracy: 0.9180 - loss: 0.2664 - val_accuracy: 0.8554 - val_loss: 0.4777\n",
      "Epoch 9/30\n",
      "73/73 - 201s - 3s/step - accuracy: 0.9033 - loss: 0.2824 - val_accuracy: 0.8678 - val_loss: 0.3591\n",
      "Epoch 10/30\n",
      "73/73 - 205s - 3s/step - accuracy: 0.9124 - loss: 0.2559 - val_accuracy: 0.8728 - val_loss: 0.4239\n",
      "Epoch 11/30\n",
      "73/73 - 198s - 3s/step - accuracy: 0.9141 - loss: 0.2686 - val_accuracy: 0.8803 - val_loss: 0.3447\n",
      "Epoch 12/30\n",
      "73/73 - 197s - 3s/step - accuracy: 0.9167 - loss: 0.2458 - val_accuracy: 0.8803 - val_loss: 0.4043\n",
      "Epoch 13/30\n",
      "73/73 - 188s - 3s/step - accuracy: 0.9228 - loss: 0.2412 - val_accuracy: 0.8728 - val_loss: 0.3640\n",
      "Epoch 14/30\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=30,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 3s/step - accuracy: 0.9081 - loss: 0.2955\n",
      "Test accuracy: 0.9087719321250916\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo en formato .keras\n",
    "model.save('./modelNella.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
