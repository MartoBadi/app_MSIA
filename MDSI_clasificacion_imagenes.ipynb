{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-11T23:15:52.73774Z",
          "iopub.status.busy": "2024-10-11T23:15:52.737332Z",
          "iopub.status.idle": "2024-10-11T23:15:56.772918Z",
          "shell.execute_reply": "2024-10-11T23:15:56.7718Z",
          "shell.execute_reply.started": "2024-10-11T23:15:52.737698Z"
        },
        "id": "JSQrQC6WemAU",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np5\n",
        "import seaborn as sns\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import random\n",
        "import time\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import shutil\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import os\n",
        "import shutil\n",
        "import kagglehub\n",
        "balabaskar_wonders_of_the_world_image_classification_path = kagglehub.dataset_download('balabaskar/wonders-of-the-world-image-classification')\n",
        "\n",
        "print('Data source import complete.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Si la celda anterior da \"likely link expired como resultado al ser ejecutada entonces hay que crear un notebook de Kaggle desde el sitio\n",
        " web del dataset, clickear en \"File\" y después en \"Open in Colab\" y hay que copiar la primera celda del notebook que se genera y reempalzarla por la que da el error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abRIwHBHtfL-"
      },
      "outputs": [],
      "source": [
        "\n",
        "seed = int(time.time())\n",
        "random.seed(seed) # Generar una semilla aleatoria basada en el tiempo actual\n",
        "\n",
        "seed = 1728676400 # Como el número que salió al correr esta celda por primera vez el 11/10/2024 a las 16:54 fue 1728676400, le asignamos este valor a la variable seed\n",
        "\n",
        "# Establecer la semilla global para Tensorflow\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "def create_directories(source_dir, dest_dirs):\n",
        "    \"\"\"\n",
        "    Crea directorios en los destinos especificados con los mismos nombres de carpetas que en el directorio de origen.\n",
        "\n",
        "    :param source_dir: Directorio de origen que contiene las carpetas.\n",
        "    :param dest_dirs: Lista de directorios de destino donde se crearán las carpetas.\n",
        "    \"\"\"\n",
        "    for category in os.listdir(source_dir):\n",
        "        category_path = os.path.join(source_dir, category)\n",
        "        if os.path.isdir(category_path):\n",
        "            for dest_dir in dest_dirs:\n",
        "                dest_category_dir = os.path.join(dest_dir, category)\n",
        "                os.makedirs(dest_category_dir, exist_ok=True)\n",
        "\n",
        "# Directorio de origen\n",
        "source_dir = '/kaggle/input/wonders-of-the-world-image-classification/Wonders of World/Wonders of World'\n",
        "\n",
        "# Directorios de destino\n",
        "train_dir = '/kaggle/working/train'\n",
        "val_dir = '/kaggle/working/val'\n",
        "test_dir = '/kaggle/working/test'\n",
        "\n",
        "# Crear directorios\n",
        "create_directories(source_dir, [train_dir, val_dir, test_dir])\n",
        "\n",
        "def split_data(source_dir, train_dir, val_dir, test_dir, val_split=0.15, test_split=0.15):\n",
        "\n",
        "    for category in os.listdir(source_dir):\n",
        "        category_path = os.path.join(source_dir, category)\n",
        "        if os.path.isdir(category_path):\n",
        "            images = os.listdir(category_path)\n",
        "            random.shuffle(images)\n",
        "            num_images = len(images)\n",
        "            num_test = int(num_images * test_split)\n",
        "            num_val = int(num_images * val_split)\n",
        "            num_train = num_images - num_test - num_val\n",
        "\n",
        "            train_images = images[:num_train]\n",
        "            val_images = images[num_train:num_train + num_val]\n",
        "            test_images = images[num_train + num_val:]\n",
        "\n",
        "            for image in train_images:\n",
        "                shutil.move(os.path.join(category_path, image), os.path.join(train_dir, category, image))\n",
        "            for image in val_images:\n",
        "                shutil.move(os.path.join(category_path, image), os.path.join(val_dir, category, image))\n",
        "            for image in test_images:\n",
        "                shutil.move(os.path.join(category_path, image), os.path.join(test_dir, category, image))\n",
        "\n",
        "# Directorios de origen y destino\n",
        "source_dir = '/kaggle/input/wonders-of-the-world-image-classification/Wonders of World/Wonders of World'\n",
        "train_dir = '/kaggle/working/train'\n",
        "val_dir = '/kaggle/working/val'\n",
        "test_dir = '/kaggle/working/test'\n",
        "\n",
        "# Dividir los datos\n",
        "split_data(source_dir, train_dir, val_dir, test_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Si la celda anterior da como resultado de la ejecución \"Failed to load (likely expired)\" hay que generar un nuevo notebook desde el sitio de kaggle del dataset y cickear \"File\" luego \"Open in Colab\" para generar un nuevo link para descargar los datos desde Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-10-11T23:15:56.776028Z",
          "iopub.status.busy": "2024-10-11T23:15:56.774802Z",
          "iopub.status.idle": "2024-10-11T23:15:57.139633Z",
          "shell.execute_reply": "2024-10-11T23:15:57.138579Z",
          "shell.execute_reply.started": "2024-10-11T23:15:56.775982Z"
        },
        "id": "MDfaSvPpemAV",
        "outputId": "f45e6707-a47f-42da-d43d-8d4ce9d640db",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2706 images belonging to 12 classes.\n",
            "Found 570 images belonging to 12 classes.\n",
            "Found 570 images belonging to 12 classes.\n"
          ]
        }
      ],
      "source": [
        "# Generadores para entrenar, validar y testear\n",
        "datagen_train = ImageDataGenerator(rescale=1./255)\n",
        "datagen_val = ImageDataGenerator(rescale=1./255)\n",
        "datagen_test = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = datagen_train.flow_from_directory(\n",
        "   '/kaggle/working/train',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    seed=seed\n",
        ")\n",
        "\n",
        "val_generator = datagen_val.flow_from_directory(\n",
        "    '/kaggle/working/val',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    seed=seed\n",
        ")\n",
        "\n",
        "test_generator = datagen_test.flow_from_directory(\n",
        "    '/kaggle/working/test',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    seed=seed\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-10-11T23:15:57.141549Z",
          "iopub.status.busy": "2024-10-11T23:15:57.141109Z",
          "iopub.status.idle": "2024-10-11T23:15:57.294829Z",
          "shell.execute_reply": "2024-10-11T23:15:57.293852Z",
          "shell.execute_reply.started": "2024-10-11T23:15:57.1415Z"
        },
        "id": "dGUK2fvOemAX",
        "outputId": "ef065d9b-10d7-4612-9cf7-8a9ed7ef2e47",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 74, 74, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 36, 36, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPoolin  (None, 17, 17, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 36992)             0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               4735104   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 12)                1548      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4829900 (18.42 MB)\n",
            "Trainable params: 4829900 (18.42 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = models.Sequential([\n",
        "    layers.InputLayer(input_shape=(150, 150, 3)),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(12, activation='softmax'),\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy']\n",
        "              )\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-10-11T23:15:57.297997Z",
          "iopub.status.busy": "2024-10-11T23:15:57.297229Z",
          "iopub.status.idle": "2024-10-11T23:26:08.847743Z",
          "shell.execute_reply": "2024-10-11T23:26:08.846744Z",
          "shell.execute_reply.started": "2024-10-11T23:15:57.297946Z"
        },
        "id": "fs81_cJTemAZ",
        "outputId": "c94070fc-2db7-4c31-8759-37c2bf031b2f",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "84/84 [==============================] - 18s 203ms/step - loss: 2.2536 - accuracy: 0.2233 - val_loss: 1.8753 - val_accuracy: 0.3676\n",
            "Epoch 2/6\n",
            "84/84 [==============================] - 17s 196ms/step - loss: 1.5575 - accuracy: 0.4843 - val_loss: 1.5294 - val_accuracy: 0.4945\n",
            "Epoch 3/6\n",
            "84/84 [==============================] - 17s 199ms/step - loss: 1.2150 - accuracy: 0.6043 - val_loss: 1.1921 - val_accuracy: 0.5956\n",
            "Epoch 4/6\n",
            "84/84 [==============================] - 17s 201ms/step - loss: 0.8331 - accuracy: 0.7345 - val_loss: 1.1278 - val_accuracy: 0.6581\n",
            "Epoch 5/6\n",
            "84/84 [==============================] - 18s 208ms/step - loss: 0.4676 - accuracy: 0.8594 - val_loss: 0.9990 - val_accuracy: 0.7279\n",
            "Epoch 6/6\n",
            "84/84 [==============================] - 17s 199ms/step - loss: 0.2311 - accuracy: 0.9304 - val_loss: 1.0509 - val_accuracy: 0.7574\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7953cc2c5c00>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps= val_generator.samples // val_generator.batch_size,\n",
        "    epochs=6\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btmByeoYemAs",
        "outputId": "f18c6946-19e8-459b-b30d-a17d83d71d35",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17/17 [==============================] - 3s 153ms/step - loss: 0.9118 - accuracy: 0.7629\n",
            "Test accuracy: 0.7628676295280457\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
        "print('Test accuracy:', test_acc)\n",
        "\n",
        "# Guardar el modelo en formato .keras\n",
        "model.save('/kaggle/working/model.keras')\n",
        "\n",
        "# Convertir el modelo a TensorFlow Lite\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Guardar el modelo convertido en formato .tflite\n",
        "with open('/kaggle/working/model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 2144356,
          "sourceId": 3569211,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30786,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
