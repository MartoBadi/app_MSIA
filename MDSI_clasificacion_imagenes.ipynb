{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 3569211,
          "sourceType": "datasetVersion",
          "datasetId": 2144356
        }
      ],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "accelerator": "TPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'wonders-of-the-world-image-classification:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F2144356%2F3569211%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20241011%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20241011T232804Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D2fadb37db77984adf1e535ab88e994dcf4ca7ff0c40dd90a948eb72dc45a5d45b6f981e1f7ebaa03c5a6eea51868a151cb65dc0c96b61011db9a9f0ca1b7fa8bd9588f10582c5d0eee381655adbb7543ec4b14a83870f4a2b129c17b426f8d05a5d8f3c432b68d84c3cdc040e30852529bd984991e220ea9c3cacbfadb532fe9c174878eba1e81e67a95ced40e9d86afed9e25c2ba864ffc098b96bf059612b7f35049004babb3c7dee62f5ea1a7443eba5cfe1919f47fd982fabb78d9d055dcf6fbb1a45f58de20ee46112b209971ab08243571774701779ecff8c5e7ce6802394e0e0dc6b066a440927820d235599dd12f08fe0b63ee03d1da96d217c1677f'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')"
      ],
      "metadata": {
        "id": "o3auICLJemAP",
        "outputId": "4255a907-e423-4f11-d74a-09facc43c560",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading wonders-of-the-world-image-classification, 453078359 bytes compressed\n",
            "[==================================================] 453078359 bytes downloaded\n",
            "Downloaded and uncompressed: wonders-of-the-world-image-classification\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import random\n",
        "import time\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import shutil\n",
        "import random"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-11T23:15:52.737332Z",
          "iopub.execute_input": "2024-10-11T23:15:52.73774Z",
          "iopub.status.idle": "2024-10-11T23:15:56.772918Z",
          "shell.execute_reply.started": "2024-10-11T23:15:52.737698Z",
          "shell.execute_reply": "2024-10-11T23:15:56.7718Z"
        },
        "trusted": true,
        "id": "JSQrQC6WemAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "seed = int(time.time())\n",
        "random.seed(seed) # Generar una semilla aleatoria basada en el tiempo actual\n",
        "\n",
        "seed = 1728676400 # Como el número que salió al correr esta celda por primera vez el 11/10/2024 a las 16:54 fue 1728676400, le asignamos este valor a la variable seed\n",
        "\n",
        "# Establecer la semilla global para Tensorflow\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "def create_directories(source_dir, dest_dirs):\n",
        "    \"\"\"\n",
        "    Crea directorios en los destinos especificados con los mismos nombres de carpetas que en el directorio de origen.\n",
        "\n",
        "    :param source_dir: Directorio de origen que contiene las carpetas.\n",
        "    :param dest_dirs: Lista de directorios de destino donde se crearán las carpetas.\n",
        "    \"\"\"\n",
        "    for category in os.listdir(source_dir):\n",
        "        category_path = os.path.join(source_dir, category)\n",
        "        if os.path.isdir(category_path):\n",
        "            for dest_dir in dest_dirs:\n",
        "                dest_category_dir = os.path.join(dest_dir, category)\n",
        "                os.makedirs(dest_category_dir, exist_ok=True)\n",
        "\n",
        "# Directorio de origen\n",
        "source_dir = '/kaggle/input/wonders-of-the-world-image-classification/Wonders of World/Wonders of World'\n",
        "\n",
        "# Directorios de destino\n",
        "train_dir = '/kaggle/working/train'\n",
        "val_dir = '/kaggle/working/val'\n",
        "test_dir = '/kaggle/working/test'\n",
        "\n",
        "# Crear directorios\n",
        "create_directories(source_dir, [train_dir, val_dir, test_dir])\n",
        "\n",
        "def split_data(source_dir, train_dir, val_dir, test_dir, val_split=0.15, test_split=0.15):\n",
        "\n",
        "    for category in os.listdir(source_dir):\n",
        "        category_path = os.path.join(source_dir, category)\n",
        "        if os.path.isdir(category_path):\n",
        "            images = os.listdir(category_path)\n",
        "            random.shuffle(images)\n",
        "            num_images = len(images)\n",
        "            num_test = int(num_images * test_split)\n",
        "            num_val = int(num_images * val_split)\n",
        "            num_train = num_images - num_test - num_val\n",
        "\n",
        "            train_images = images[:num_train]\n",
        "            val_images = images[num_train:num_train + num_val]\n",
        "            test_images = images[num_train + num_val:]\n",
        "\n",
        "            for image in train_images:\n",
        "                shutil.move(os.path.join(category_path, image), os.path.join(train_dir, category, image))\n",
        "            for image in val_images:\n",
        "                shutil.move(os.path.join(category_path, image), os.path.join(val_dir, category, image))\n",
        "            for image in test_images:\n",
        "                shutil.move(os.path.join(category_path, image), os.path.join(test_dir, category, image))\n",
        "\n",
        "# Directorios de origen y destino\n",
        "source_dir = '/kaggle/input/wonders-of-the-world-image-classification/Wonders of World/Wonders of World'\n",
        "train_dir = '/kaggle/working/train'\n",
        "val_dir = '/kaggle/working/val'\n",
        "test_dir = '/kaggle/working/test'\n",
        "\n",
        "# Dividir los datos\n",
        "split_data(source_dir, train_dir, val_dir, test_dir)"
      ],
      "metadata": {
        "id": "abRIwHBHtfL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generadores para entrenar, validar y testear\n",
        "datagen_train = ImageDataGenerator(rescale=1./255)\n",
        "datagen_val = ImageDataGenerator(rescale=1./255)\n",
        "datagen_test = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = datagen_train.flow_from_directory(\n",
        "   '/kaggle/working/train',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    seed=seed\n",
        ")\n",
        "\n",
        "val_generator = datagen_val.flow_from_directory(\n",
        "    '/kaggle/working/val',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    seed=seed\n",
        ")\n",
        "\n",
        "test_generator = datagen_test.flow_from_directory(\n",
        "    '/kaggle/working/test',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    seed=seed\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-11T23:15:56.774802Z",
          "iopub.execute_input": "2024-10-11T23:15:56.776028Z",
          "iopub.status.idle": "2024-10-11T23:15:57.139633Z",
          "shell.execute_reply.started": "2024-10-11T23:15:56.775982Z",
          "shell.execute_reply": "2024-10-11T23:15:57.138579Z"
        },
        "trusted": true,
        "id": "MDfaSvPpemAV",
        "outputId": "f45e6707-a47f-42da-d43d-8d4ce9d640db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2706 images belonging to 12 classes.\n",
            "Found 570 images belonging to 12 classes.\n",
            "Found 570 images belonging to 12 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential([\n",
        "    layers.InputLayer(input_shape=(150, 150, 3)),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(12, activation='softmax'),\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy']\n",
        "              )\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-11T23:15:57.141109Z",
          "iopub.execute_input": "2024-10-11T23:15:57.141549Z",
          "iopub.status.idle": "2024-10-11T23:15:57.294829Z",
          "shell.execute_reply.started": "2024-10-11T23:15:57.1415Z",
          "shell.execute_reply": "2024-10-11T23:15:57.293852Z"
        },
        "trusted": true,
        "id": "dGUK2fvOemAX",
        "outputId": "ef065d9b-10d7-4612-9cf7-8a9ed7ef2e47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 74, 74, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 36, 36, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPoolin  (None, 17, 17, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 36992)             0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               4735104   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 12)                1548      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4829900 (18.42 MB)\n",
            "Trainable params: 4829900 (18.42 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps= val_generator.samples // val_generator.batch_size,\n",
        "    epochs=6\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-11T23:15:57.297229Z",
          "iopub.execute_input": "2024-10-11T23:15:57.297997Z",
          "iopub.status.idle": "2024-10-11T23:26:08.847743Z",
          "shell.execute_reply.started": "2024-10-11T23:15:57.297946Z",
          "shell.execute_reply": "2024-10-11T23:26:08.846744Z"
        },
        "trusted": true,
        "id": "fs81_cJTemAZ",
        "outputId": "c94070fc-2db7-4c31-8759-37c2bf031b2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "84/84 [==============================] - 18s 203ms/step - loss: 2.2536 - accuracy: 0.2233 - val_loss: 1.8753 - val_accuracy: 0.3676\n",
            "Epoch 2/6\n",
            "84/84 [==============================] - 17s 196ms/step - loss: 1.5575 - accuracy: 0.4843 - val_loss: 1.5294 - val_accuracy: 0.4945\n",
            "Epoch 3/6\n",
            "84/84 [==============================] - 17s 199ms/step - loss: 1.2150 - accuracy: 0.6043 - val_loss: 1.1921 - val_accuracy: 0.5956\n",
            "Epoch 4/6\n",
            "84/84 [==============================] - 17s 201ms/step - loss: 0.8331 - accuracy: 0.7345 - val_loss: 1.1278 - val_accuracy: 0.6581\n",
            "Epoch 5/6\n",
            "84/84 [==============================] - 18s 208ms/step - loss: 0.4676 - accuracy: 0.8594 - val_loss: 0.9990 - val_accuracy: 0.7279\n",
            "Epoch 6/6\n",
            "84/84 [==============================] - 17s 199ms/step - loss: 0.2311 - accuracy: 0.9304 - val_loss: 1.0509 - val_accuracy: 0.7574\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7953cc2c5c00>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
        "print('Test accuracy:', test_acc)\n",
        "\n",
        "# Guardar el modelo en formato .keras\n",
        "model.save('/kaggle/working/model.keras')\n",
        "\n",
        "# Convertir el modelo a TensorFlow Lite\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Guardar el modelo convertido en formato .tflite\n",
        "with open('/kaggle/working/model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)"
      ],
      "metadata": {
        "trusted": true,
        "id": "btmByeoYemAs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f18c6946-19e8-459b-b30d-a17d83d71d35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17/17 [==============================] - 3s 153ms/step - loss: 0.9118 - accuracy: 0.7629\n",
            "Test accuracy: 0.7628676295280457\n"
          ]
        }
      ]
    }
  ]
}